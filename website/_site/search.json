[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "From 2019 to 2023, COVID-19 has profoundly impacted various facets of our lives, including education and communication. In response, the adoption of effective countermeasures to mitigate the spread of the virus has been imperative. Academic research supports the efficacy of facial masks in significantly reducing virus transmission, which has subsequently catalyzed the development of mask recognition systems. These systems predominantly utilize image recognition technologies to ascertain mask compliance among individuals."
  },
  {
    "objectID": "index.html#data-science-question",
    "href": "index.html#data-science-question",
    "title": "Introduction",
    "section": "Data Science Question",
    "text": "Data Science Question\nThe impact of COVID-19 has been profound and multi-faceted, affecting nearly every aspect of life globally. Two of the most significant impacts have been on human life and the global economy.\nCOVID-19 has resulted in a tragic loss of life worldwide. Globally, as of 3:52pm CET, 30 November 2023, there have been 772,052,752 confirmed cases of COVID-19, including 6,985,278 deaths, reported to WHO. This loss has not only been a human tragedy but has also had psychological and social repercussions, affecting the mental health of communities and changing the way people mourn and grieve.\n\nThe pandemic has had a devastating impact on the global economy. To control the spread of the virus, many countries implemented lockdowns and social distancing measures, which led to a dramatic slowdown in economic activities. Key sectors such as travel, hospitality, and retail were particularly hard hit. The economic disruption caused widespread job losses, business closures, and financial strain for individuals and families. Governments around the world have had to inject substantial fiscal stimulus to support their economies, leading to increased national debts.\nOverall, the COVID-19 pandemic has been a defining global crisis of the early 21st century, with its impacts likely to be felt for many years to come. Consequently, I believe that a thorough analysis of the factors affecting COVID-19’s transmission and mortality is imperative. Such an investigation will enhance our comprehension of, and preparedness for, any future global pandemics. By understanding the variables that influence the spread and lethality of such diseases, we can develop more effective strategies to curb their proliferation and minimize fatalities. This proactive approach is vital to safeguard public health and preserve lives."
  },
  {
    "objectID": "index.html#literature-review",
    "href": "index.html#literature-review",
    "title": "Introduction",
    "section": "Literature Review",
    "text": "Literature Review\n\nPopulation Density and the Transmission of COVID-19\nThe COVID-19 pandemic has prompted extensive research into factors influencing its spread. A significant area of focus has been the role of population density.\nSy et al. (2021) conducted a comprehensive study across U.S. counties, revealing a strong correlation between population density and the basic reproductive number (R0) of COVID-19. They found that areas with higher population densities experienced greater transmission rates, likely due to increased interpersonal contact. The study identified a critical population density threshold necessary to sustain an outbreak, emphasizing the significance of population density in virus transmission dynamics (Sy et al., 2021).\nIn a study focusing on Turkey, Coşkun et al. (2021) explored the combined effect of population density and wind on COVID-19 spread. They concluded that these factors accounted for a significant portion of the variance in virus transmission. The study highlighted that wind, by increasing air circulation, could exacerbate the spread in denser areas, thus underlining the complex interplay between environmental factors and population density in the pandemic’s trajectory (Coşkun et al., 2021).\nYin et al. (2021) investigated the association between population density and COVID-19 infection rates in both China and the USA. Their findings underscored a positive correlation, particularly in regions with severe outbreaks. The study supported the efficacy of social distancing and travel restrictions, pointing out the critical role of population density in managing the spread of the virus (Yin et al., 2021).\nLastly, Wong and Li (2020) presented a study demonstrating that population density was an effective predictor of cumulative infection cases in U.S. counties. Their research incorporated additional demographic variables, such as the percentages of African Americans and Hispanic-Latinas, finding that while these factors influenced infection rates, the impact of population density remained consistently significant. This study highlighted the necessity of including population density in predictive models for COVID-19 spread (Wong & Li, 2020).\nIn conclusion, these studies collectively underscore the crucial role of population density in the transmission dynamics of COVID-19.\n\n\nVaccination and the Infection/Death Rates of COVID-19\nThe onset of the COVID-19 pandemic has prompted unprecedented global efforts in vaccine development and distribution at the same time. As vaccination campaigns roll out worldwide, it becomes crucial to evaluate their impact on reducing infection and mortality rates.\nA study by the BMJ (2023) conducted a comprehensive observational study to assess the public health impact of COVID-19 vaccines across counties in the United States. Using data from December 2020 to December 2021, the study utilized generalized linear mixed models to explore the association between vaccination coverage and the rates of COVID-19 cases and deaths. The study’s findings indicate a significant reduction in COVID-19 cases and deaths correlating with increased vaccination coverage, even when accounting for social vulnerability and community mobility (The BMJ, 2023).\nSimilarly, another study published in Scientific Reports (2023) analyzed the impact of COVID-19 vaccination on the pandemic’s trajectory in various U.S. states. This study focused on the average treatment effect of vaccination on the growth rates of total cases and hospitalizations. It found that COVID-19 vaccines have significantly slowed the pandemic, with a notable reduction in the number of cases and hospitalizations. This study also explored potential biases and the heterogeneous effects of vaccination across different states, finding no significant differences based on demographic or political factors (Scientific Reports, 2023).\nExpanding the scope to a global perspective, a study indexed in PubMed (2023) analyzed the effect of COVID-19 vaccination on daily cases and deaths worldwide. The study demonstrated that increased vaccination rates are associated with a decrease in new COVID-19 cases and deaths globally. However, it also highlighted the challenges of unequal vaccine distribution across countries, emphasizing the need for fair and accelerated distribution to combat the pandemic effectively (PubMed, 2023).\nCollectively, these studies offer robust evidence of the positive impact of COVID-19 vaccination campaigns on reducing infection and mortality rates."
  },
  {
    "objectID": "index.html#summary",
    "href": "index.html#summary",
    "title": "Introduction",
    "section": "Summary",
    "text": "Summary\nIn this study, the CNN model was initially trained on avatar images to recognize face masks, achieving an impressive accuracy of 91%. Subsequent incorporation of an attention mechanism into the CNN architecture further elevated the model’s accuracy to 96%. These findings affirm the robust capability of CNNs in training for face mask recognition, with the addition of the attention mechanism notably enhancing discriminative accuracy. Lastly, we delve into the model’s limitations and the potential challenges encountered in real-world implementations."
  },
  {
    "objectID": "Data-Sources.html",
    "href": "Data-Sources.html",
    "title": "Data Sources",
    "section": "",
    "text": "The dataset used in our study is Face Mask Detection ~12K Images Dataset, which is used for Face Mask Detection Classification with images. The dataset consists of almost 12K images which are almost 328.92MB in size.\n\n\n\nSo Many Faces We Have!"
  },
  {
    "objectID": "Data-Sources.html#our-world-in-data-owid-covid-19-data",
    "href": "Data-Sources.html#our-world-in-data-owid-covid-19-data",
    "title": "Data Sources",
    "section": "",
    "text": "The Our World in Data The dataset used in our study is Face Mask Detection ~12K Images Dataset, which is used for Face Mask Detection Classification with images. The dataset consists of almost 12K images which are almost 328.92MB in size.consists of facial headshots. This focus on the face simplifies the process by minimizing background distractions. However, the photos vary in pixel count and dimensions, requiring a standardization to a uniform resolution of 150x150 pixels.\n\n\n\nClick on the logo to access the sample data of US!"
  },
  {
    "objectID": "Data-Sources.html#key-attributes",
    "href": "Data-Sources.html#key-attributes",
    "title": "Data Sources",
    "section": "Key Attributes",
    "text": "Key Attributes\n\n\n\n\n\n\n\n\nimage_path\nlabel\nlocation\n\n\n\n\ninput/Face Mask Dataset/Test/WithoutMask/2734.png\nWithoutMask\nTest\n\n\ninput/Face Mask Dataset/Test/WithoutMask/4345.png\nWithoutMask\nTest\n\n\ninput/Face Mask Dataset/Test/WithoutMask/4423.png\nWithoutMask\nTest\n\n\ninput/Face Mask Dataset/Test/WithoutMask/2052.png\nWithoutMask\nTest\n\n\ninput/Face Mask Dataset/Test/WithoutMask/3364.png\nWithoutMask\nTest"
  },
  {
    "objectID": "Data-Sources.html#data-cleaning",
    "href": "Data-Sources.html#data-cleaning",
    "title": "Data Sources",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nThe data set provided by OWID is very complete, and I only need to do some simple data cleaning work, including converting column formats and using interpolation to deal with a small number of missing values."
  },
  {
    "objectID": "Reference.html",
    "href": "Reference.html",
    "title": "Reference",
    "section": "",
    "text": "Pann, V.; Lee, H.J. Effective Attention-Based Mechanism for Masked Face Recognition. Appl. Sci. 2022, 12, 5590. https://doi.org/10.3390/app12115590\nAlzu’bi, A.; Albalas, F.; AL-Hadhrami, T.; Younis, L.B.; Bashayreh, A. Masked Face Recognition Using Deep Learning: A Review. Electronics 2021, 10, 2666. https://doi.org/10.3390/electronics10212666\nhttps://www.kaggle.com/code/egbeolajohn/facewmask-detection-with-98-5-accuracy/notebook?scriptVersionId=93916875\nhttps://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset/data"
  },
  {
    "objectID": "Conclusion.html",
    "href": "Conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "The integration of attention mechanisms into a convolutional neural network (CNN) for face mask recognition has demonstrated considerable improvements in model performance. The comparison between the two models—the original CNN and the enhanced CNN with attention mechanisms—reveals several key enhancements.\n\nThe original CNN model achieved an accuracy of 91.63% on the testing dataset, which is commendable. However, with the introduction of attention mechanisms, the accuracy increased significantly to 96.37%. This improvement underscores the capability of attention mechanisms to fine-tune the focus of the network on more critical and informative features within the data.\nThe confusion matrix for the CNN with the attention mechanism shows a dramatic reduction in false negatives for class 0, dropping from 82 to just 3. This indicates a higher sensitivity to detecting class 0 correctly. Although there was an increase in false positives, the overall error rate decreased, illustrating the model’s enhanced ability to generalize across different types of data input.\n\n\nLimitations and Future Prospects\nLimitations:\n\nGeneralization to Varied Data: One limitation observed is the model’s potential overfitting to specific types of face masks or facial features not well-represented in the training data.\nComputational Complexity: Attention mechanisms, while powerful, increase the computational complexity and may lead to longer training times, which could be a constraint in resource-limited settings.\n\nFuture Prospects:\n\nRobustness across Diverse Scenarios: Future improvements could focus on enhancing the robustness of the model to perform consistently across a more diverse set of face masks and environmental conditions. This could involve collecting a more varied dataset that includes a wider range of face mask types and facial expressions.\nReal-time Processing: Optimizing the model for real-time processing could extend its application to dynamic environments, such as surveillance and mobile applications, where quick and efficient mask detection is required.\nIntegration with Other Modalities: Combining the visual data with other modalities, such as thermal imaging, could improve detection capabilities, especially in scenarios where face masks are used alongside other personal protective equipment.\n\nAdvanced Attention Mechanisms:\n\nMulti-Scale Attention: Implementing multi-scale attention mechanisms could help the model pay attention to both local and global features effectively, improving its accuracy and robustness.\nCross-Modal Attention: For applications involving multiple input types (e.g., video and audio), cross-modal attention mechanisms could enhance the model’s ability to focus on more informative cues across different data types.\n\nIn conclusion, the introduction of attention mechanisms to CNN models for face mask recognition not only improves accuracy but also enhances the model’s ability to focus on relevant features, thus reducing overall error rates. Despite the increased computational demands, the benefits of such mechanisms in specialized applications like mask recognition suggest a promising direction for future research and development."
  },
  {
    "objectID": "Data-Sources.html#face-mask-detection-12k-images-dataset",
    "href": "Data-Sources.html#face-mask-detection-12k-images-dataset",
    "title": "Data Sources",
    "section": "",
    "text": "The dataset used in our study is Face Mask Detection ~12K Images Dataset, which is used for Face Mask Detection Classification with images. The dataset consists of almost 12K images which are almost 328.92MB in size.\n\n\n\nSo Many Faces We Have!"
  },
  {
    "objectID": "Data-Sources.html#data-preprocessing",
    "href": "Data-Sources.html#data-preprocessing",
    "title": "Data Sources",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nThe data set is divided in training, testing and validation directories.\n\n\n\nTraining Example\n\n\n\n\n\nTesting Example\n\n\n\n\n\nValidation Example\n\n\nThe dataset employed in this study comprises facial headshots, which inherently simplifies the analytical process by minimizing extraneous background distractions. Nevertheless, the images exhibit variability in pixel count and dimensions, necessitating their standardization to a uniform resolution of 150x150 pixels to ensure consistency in the data processing and analysis."
  },
  {
    "objectID": "index.html#related-work",
    "href": "index.html#related-work",
    "title": "Introduction",
    "section": "Related Work",
    "text": "Related Work\nConvolutional Neural Networks (CNNs) are effectively used for face mask recognition by leveraging their ability to process pixel data from images and learn hierarchical features. CNNs employ multiple layers of filters to extract features from an image. In the context of masked faces, these networks focus on extracting and learning the visible parts of the face, such as the eyes and forehead. This allows the model to recognize individuals even when lower facial features are obscured by masks, by adapting the training process to focus more on the unmasked regions of the face.\nRecent studies in face mask recognition using CNNs have introduced several advancements. Pann & Lee (2022) have pioneered an attention-based CNN model that employs a convolutional block attention module (CBAM), focusing on enhancing feature recognition particularly around the eye regions, which is critical in scenarios where masks obscure facial features. Concurrently, Zhang et al. (2021) present a development in lightweight CNN architectures aimed at real-time face mask detection, balancing computational efficiency with performance. These studies underscore a critical shift towards adapting facial recognition technologies to accommodate scenarios involving face coverings, highlighting both the innovative approach to feature enhancement and the pragmatic application in real-time environments."
  },
  {
    "objectID": "Models.html",
    "href": "Models.html",
    "title": "Models",
    "section": "",
    "text": "We developed our model using a convolutional neural network architecture, starting with a convolutional layer of 64 filters followed by max pooling and batch normalization. This initial setup is complemented by successive convolutional layers with 128 and 256 filters respectively, each followed by max pooling and batch normalization to enhance the model’s learning capability. Regularization is achieved through dropout at a rate of 0.25 after each convolutional block to prevent overfitting. The network concludes with a fully connected layer of 256 neurons, employing a ReLU activation function, and a dropout rate of 0.5 to further enforce regularization. The output layer consists of a single neuron with a sigmoid activation function, making the model suitable for binary classification tasks. The model utilizes the Adam optimizer and is trained with a binary cross-entropy loss function, focusing on binary accuracy as the performance metric.\n\n\n\nAccuracyLoss\n\n\n\n\n\nFigure 1-1: This figure shows the training and validation accuracy of the model across epochs. Initially, the training accuracy starts high and remains quite stable, showing little improvement over time, which suggests the model quickly reached a good performance level on the training data. In contrast, the validation accuracy starts much lower, indicating initial underperformance on unseen data, but it significantly improves by the second epoch and then stabilizes, closely mirroring the training accuracy by the fifth epoch. This could suggest that the model, after some adjustments, is generalizing well without overfitting or underfitting.\n\n\n\n\n\n\n\nFigure 1-2: This figure shows the training and validation loss over the epochs. The training loss starts lower and decreases steadily, reflecting the model’s learning progress on the training data. The validation loss starts very high, indicating poor initial performance on the validation set, but it sharply decreases and eventually stabilizes, though with some fluctuation. This reduction in validation loss alongside a stable, low training loss suggests that the model is becoming more effective and consistent in its predictions as it trains.\n\n\n\n\n\n\n\n\nThe model’s accuracy on the testing dataset is 91.63%. This high level of accuracy suggests that the model is performing well on the given task.\n\n\n\nFigure 2: This figure shows that the model has a high rate of correct predictions for both classes, with a particularly low number of false positives, indicating strong performance in distinguishing class 1. However, there are more false negatives for class 0, which could be an area for improvement in model accuracy."
  },
  {
    "objectID": "Models.html#related-work",
    "href": "Models.html#related-work",
    "title": "Models",
    "section": "Related Work",
    "text": "Related Work\nConvolutional Neural Networks (CNNs) are effectively used for face mask recognition by leveraging their ability to process pixel data from images and learn hierarchical features. CNNs employ multiple layers of filters to extract features from an image. In the context of masked faces, these networks focus on extracting and learning the visible parts of the face, such as the eyes and forehead. This allows the model to recognize individuals even when lower facial features are obscured by masks, by adapting the training process to focus more on the unmasked regions of the face.\nRecent studies in face mask recognition using CNNs have introduced several advancements. Pann & Lee (2022) have pioneered an attention-based CNN model that employs a convolutional block attention module (CBAM), focusing on enhancing feature recognition particularly around the eye regions, which is critical in scenarios where masks obscure facial features. Concurrently, Zhang et al. (2021) present a development in lightweight CNN architectures aimed at real-time face mask detection, balancing computational efficiency with performance. These studies underscore a critical shift towards adapting facial recognition technologies to accommodate scenarios involving face coverings, highlighting both the innovative approach to feature enhancement and the pragmatic application in real-time environments."
  },
  {
    "objectID": "Models.html#convolutional-neural-networks-model",
    "href": "Models.html#convolutional-neural-networks-model",
    "title": "Models",
    "section": "",
    "text": "We developed our model using a convolutional neural network architecture, starting with a convolutional layer of 64 filters followed by max pooling and batch normalization. This initial setup is complemented by successive convolutional layers with 128 and 256 filters respectively, each followed by max pooling and batch normalization to enhance the model’s learning capability. Regularization is achieved through dropout at a rate of 0.25 after each convolutional block to prevent overfitting. The network concludes with a fully connected layer of 256 neurons, employing a ReLU activation function, and a dropout rate of 0.5 to further enforce regularization. The output layer consists of a single neuron with a sigmoid activation function, making the model suitable for binary classification tasks. The model utilizes the Adam optimizer and is trained with a binary cross-entropy loss function, focusing on binary accuracy as the performance metric.\n\n\n\nAccuracyLoss\n\n\n\n\n\nFigure 1-1: This figure shows the training and validation accuracy of the model across epochs. Initially, the training accuracy starts high and remains quite stable, showing little improvement over time, which suggests the model quickly reached a good performance level on the training data. In contrast, the validation accuracy starts much lower, indicating initial underperformance on unseen data, but it significantly improves by the second epoch and then stabilizes, closely mirroring the training accuracy by the fifth epoch. This could suggest that the model, after some adjustments, is generalizing well without overfitting or underfitting.\n\n\n\n\n\n\n\nFigure 1-2: This figure shows the training and validation loss over the epochs. The training loss starts lower and decreases steadily, reflecting the model’s learning progress on the training data. The validation loss starts very high, indicating poor initial performance on the validation set, but it sharply decreases and eventually stabilizes, though with some fluctuation. This reduction in validation loss alongside a stable, low training loss suggests that the model is becoming more effective and consistent in its predictions as it trains.\n\n\n\n\n\n\n\n\nThe model’s accuracy on the testing dataset is 91.63%. This high level of accuracy suggests that the model is performing well on the given task.\n\n\n\nFigure 2: This figure shows that the model has a high rate of correct predictions for both classes, with a particularly low number of false positives, indicating strong performance in distinguishing class 1. However, there are more false negatives for class 0, which could be an area for improvement in model accuracy."
  },
  {
    "objectID": "Models.html#cnn-model-with-attention-mechanism",
    "href": "Models.html#cnn-model-with-attention-mechanism",
    "title": "Models",
    "section": "CNN Model with Attention Mechanism",
    "text": "CNN Model with Attention Mechanism\nWe integrated two types of attention mechanisms into the Convolutional Neural Network (CNN) model:\n\nChannel Attention Mechanism:\n\nThe ChannelAttention layer works by focusing on the ‘what’ of the input data, which means it helps the model pay more attention to the most informative features across the channel dimension. This layer performs the following steps:\n\nAverage Pooling and Max Pooling: These operations are applied to the input tensor along the spatial dimensions (width and height), resulting in two different context descriptors: one for the average and one for the maximum values.\nShared Dense Layers: Two shared dense layers transform these context descriptors. The first dense layer with a relu activation reduces dimensionality by a factor defined by ratio, which controls the trade-off between complexity and performance. The second dense layer restores the dimensions.\nActivation Function: The outputs of the dense layers from the average-pooled and max-pooled paths are added and passed through a sigmoid activation function to produce a scaling factor between 0 and 1.\n\nThese steps generate a channel-wise attention map which is then multiplied by the original input tensor to scale the channel features by their importance.\n\nSpatial Attention Mechanism:\n\nThe SpatialAttention layer, on the other hand, focuses on the ‘where’ of the input data, directing the model’s focus to important spatial locations:\n\nPooling Operations: Average and max pooling operations are applied along the channel axis to produce two separate feature maps, highlighting where significant activations occur across all channels.\nConcatenation and Convolution: The feature maps are concatenated and passed through a convolutional layer with a single filter and a sigmoid activation. This filter generates a spatial attention map, which is learned based on the concatenated contexts of average and max signals.\n\nThe spatial attention map emphasizes specific areas in the input tensor, enabling the model to focus more on salient parts of the image.\nBoth attention mechanisms are integrated after batch normalization and before the dropout layer in each convolutional block of the model. This placement ensures that the attention modules can refine the feature representation post-normalization and before any feature dropout occurs, maintaining the focus on important features throughout the training. By implementing these attention layers, the CNN model becomes more adaptive and focused, improving its ability to recognize patterns, especially in complex visual tasks such as recognizing faces with masks. The attention mechanisms can help mitigate issues like the variance in mask types, positions, and the occlusion they cause by directing the model to focus more on the visible, unoccluded parts of the face.\n\nTraining Process\n\nAccuracyLoss\n\n\n\n\n\nFigure 3-1: This figure shows the training and validation accuracy of the model across six epochs after integrating the attention mechanism. The training accuracy begins high and remains consistent, suggesting the model achieves strong performance on the training data early. The validation accuracy initially shows underperformance but improves dramatically around the third epoch, leveling out to closely match the training accuracy by the sixth epoch. This stability in both training and validation accuracy suggests effective generalization and indicates that the model is well-tuned to the complexities of the task without overfitting.\n\n\n\n\n\n\n\nFigure 3-2: This figure shows the training and validation loss over six epochs. The training loss decreases rapidly and stabilizes at a low level from the third epoch onward, which is indicative of effective learning. The validation loss, although starting higher, mirrors this trend by the third epoch and closely follows the training loss, showing a reduction to a similar low level. This convergence of training and validation losses at low values signifies that the model, enhanced with attention mechanisms, is consistent and robust against overfitting.\n\n\n\n\n\nComparing these results with the previous plots without the attention mechanism, it is evident that the introduction of attention layers has improved the model’s ability to generalize as shown by the reduced gap between training and validation accuracy and loss. Previously, there were significant drops and spikes in validation accuracy and loss, suggesting potential issues with model stability and generalization. With the attention mechanism, these issues seem to have been mitigated, leading to a more stable and reliable model performance across epochs. This improvement likely results from the model’s enhanced capability to focus on the most informative features, reducing the noise and the effects of irrelevant data variations during training.\n\n\nTesting Results\nThe accuracy on the testing data for the CNN model with the attention mechanism is 96.37%, showing a significant improvement over the previous accuracy of 91.63%. This enhancement can be attributed both to the incorporation of the attention mechanism and the observed changes in the confusion matrix.\n\n\n\nFigure 4: This figure represents a confusion matrix for the CNN model enhanced with an attention mechanism, showing the number of correct and incorrect predictions for two classes (0 and 1) after testing.\n\n\nComparing this confusion matrix to the previous one without the attention mechanism, there is a notable improvement in both the false negatives and false positives rates. Previously, the model had a higher number of false negatives for class 0 (82 instances) and only one false positive. In the updated model with attention mechanisms, the number of false negatives dramatically decreased to 3, significantly improving the sensitivity of the model towards class 0. The false positives slightly increased from 1 to 33, indicating a slight trade-off where the model has become more cautious about incorrectly classifying class 1 but at the cost of occasionally misclassifying class 0 as class 1.\nThis enhanced confusion matrix suggests that the attention mechanism has successfully increased the model’s ability to focus on more discriminative features for both classes, thereby reducing the overall error rates and specifically the rate at which the model misses class 0 instances. However, the increase in false positives indicates that while the model is less likely to miss class 0 instances, it might be overcompensating, leading to more class 1 instances being incorrectly classified as class 0. This could be an area for further refinement in balancing the sensitivity and specificity of the model."
  },
  {
    "objectID": "Models.html#comparison",
    "href": "Models.html#comparison",
    "title": "Models",
    "section": "Comparison",
    "text": "Comparison"
  },
  {
    "objectID": "Models.html#summary",
    "href": "Models.html#summary",
    "title": "Models",
    "section": "Summary",
    "text": "Summary\nOverall, the results indicate that the CNN model with attention mechanism is a well-balanced model that is both more sensitive and just slightly less specific, resulting in higher overall accuracy and improved performance on the testing dataset. This makes the model more reliable for practical applications, where high accuracy is critical."
  }
]